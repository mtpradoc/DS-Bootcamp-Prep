# Pre- Work - Data science Fundamentals
Dive into a series of self-paced lessons on the essentials of Python programming and applied math for data science before the course beigns.

- Explore fundamental Python programming concepts, including variables, lists, loops, dictionaries, and data sets.
- Leverage programming tools like GitHub and the command line interface to manage data science projects.
- Practice solving coding challenges similar to the questions used in task-based data science interviews.
- Write and run Python functions using multiple arguments.
- Discover how key math concepts like statistical significance and probability distribution are applied throughout data science.

# Unit 1 - Fundamentals
Get acquainted with essential data science tools and techniques, working in a programming environment to gather, organize, and share projets and ta with Git and UNIX.

- Demonstrate familiarity with intriductory programming concepts uing Python and Numpy to navigate data sources and collections.
- Utilize UNIX commands to navigate file systems and modify files.
- Learn to track changes and iterations using Git version control from your terminal.
- Define and apply descriptive statistical fundamentals to sample data sets.
- Practice Plotting and visualizing data using Python libraries like Matplotlib and Seaborn.

**Project**: Apply Numpy and Python programming skills to answr questions based on a clean data set.

# Unit 2 - Exploratory Data Analysis
Perform exploratory data analysis. Generative visual and statistial analyses, using Python and its associated libraries and tools to approach problems in fields like finance, marketing, and public policy.

- Design an experimental study with a well-thoughtout problem statement and data framework. 
- Use Pandas to read, clean, parse, and plot data, extracting and rearranging data through indexing, grouping, and JOINing.
- Review statistical testing concepts (p values, confidente intervals, lambda functions, correlation/causation) with SciPy and StatsModels.
- Learn to scrape website data using popular scraping tools.
- Explore bootstrapping, resampling, and building inferences about your data.

**Project**: Leverage Pandas to apply advanced Numpy and Python skills cleaning, analyzing, and testing data from multiple messy data sets.

# Unit 3 - Classical Statistical Modeling
Explore effective study design and model evaluation and optimization, implementing linear and logisti regression, and classification models. Collet and connect external data to add nuance to your models using web scraping and APIs.

- Use scikit-learn and StatsModels to run linear and logistic regeression models and learn to evaluate model fit.
- Beign to look at classification models by implementing the k-nearest neighbors (kNN) algorithm.
- Articualate the bias-variance trade-off as you practive evaluating classical statistical models.
- Use feature selection to deepen your knowledge of study design and model evaluation.
- Learn to apply optimization and regularization for fitting and tuning models.
- Dive into the math and theory behind how gradient descent helps to optimize loss functions for machine learning models.

**Project**: Explore, clean, and model data based on a provided data set, outlining your strategy and explaining your results.

# Unit 4 - Machine Learning Models
Build machine learning models. Explore the differences between supervised and unsupervised learning via clustering, natural language processing, and neural networks.

- Define clustering and its advantages and disadvantages as compared to classification models.
- Build and evaluate ensemble models using decision trees, random forests, bagging, and boosting.
- Get acquainted with natural language processing (NLP) through sentiment analysis of scraped website data.
- Learn how Naive Bayes can simplify the process of analyzing data for supervised learning algorithms.
- Explore the history and use of Hadoop, as well as the advantages and disadvantages of using parallel or distributed systems to store, access, and analyze big data.
- Understand how Hive interacts with Hadoop and discover Spark's advantages through big data case studies.
- Analyze and model time series data using the ARIMA model.

**Project**: Students will scrape and model their own data using multiple methods, outlining their approach and evaluating any risks or limitations.

# Unit 5 - Advanced Topics and Trends
Dive deeper into recommender systems, neural networks, and computer vision models, implementing what you've learned to productize models.

- Compare and contrast different types of neural networks and demonstrate how they are fit with back propagation.
- Build and apply basic recommender systems in order to predict on sample user data.
- Work with career coaches to create and polish your professional portfolio.
- Practice with data science case studies to prepare for job interviews.

**Project**: Choose a data set to explore and model, providing a detailed notebook of your technical approach and a public presentation on your findings.
